[0;33mNO_NFS mode enabled : nodes can be from different sites[0m
[0;36mReading configuration from [0;33moutput_logs_test7/with_6_machines/config6.txt[0m...
[0;32mMaster site name set to: [0;33mrennes[0m
[0;32mMaster node name set to: [0;33mparadoxe-1[0m
[0;32mMaster node IP set to: [0;33m172.16.101.1[0m
[0;32mMaster node port set to: [0;33m3000[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-16[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-11[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-26[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-24[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-25[0m
[0;36mConfiguration reading complete.[0m
[0;36mKilling ServeFile on [0;33mparadoxe-1[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-1[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-16[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-16[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-11[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-11[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-26[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-26[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-24[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-24[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-25[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-25[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling FileLocatorServer on [0;33mparadoxe-1[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-1[0;36m: [0;35mpkill -f java\ FileLocatorServer\ 9999[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-1[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-1[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test7[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-16[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-16[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test7[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-11[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-11[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test7[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-26[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-26[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test7[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-24[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-24[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test7[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-25[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-25[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test7[0m
[0;36mLaunching FileLocatorServer on [0;33mparadoxe-1[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-1[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java  FileLocatorServer 9999 /tmp/systemes-distribues/src/test/resources/test7[0m
Server started on port 8888
Server started on port 8888
Server started on port 8888
File Locator Server is running on port 9999...
Server started on port 8888
Server started on port 8888
Server started on port 8888
[0;36mSubmitting Spark app from [0;33mparadoxe-1[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-1[0;36m: [0;35m
        /home/anasmane/spark-3.5.3-bin-hadoop3/bin/spark-submit --master spark://172.16.101.1:3000 --driver-memory 50G --executor-memory 50G --conf 'spark.executor.extraJavaOptions=-XX:-UseGCOverheadLimit' --conf 'spark.driver.extraJavaOptions=-XX:-UseGCOverheadLimit' --deploy-mode client --class Main /tmp/systemes-distribues/target/distributed-make-project-1.0.jar /tmp/systemes-distribues/src/test/resources/test7/Makefile all spark://172.16.101.1:3000 NO_NFS
    [0m
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
[33mSkipping last target 'all' (no commands).[0m

[32m==============================[0m
[32m  Global Time : 93.072500716 seconds  [0m
[32m==============================[0m
[33m--------------------------------[0m
	[33mParsing Time           : 0.014116306 seconds[0m
	[33mGraph Build Time       : 0.090853712 seconds[0m
	[33mSpark Configuration Time: 1.192210768 seconds[0m
	[33mExecution Time         : 91.775290568 seconds[0m
[33m--------------------------------[0m
[0;36mKilling ServeFile on [0;33mparadoxe-1[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-1[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-16[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-16[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-11[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-11[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-26[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-26[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-24[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-24[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-25[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-25[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling FileLocatorServer on [0;33mparadoxe-1[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-1[0;36m: [0;35mpkill -f java\ FileLocatorServer\ 9999[0m
24/12/16 18:48:58 INFO SparkContext: Running Spark version 3.5.3
24/12/16 18:48:58 INFO SparkContext: OS info Linux, 5.10.0-33-amd64, amd64
24/12/16 18:48:58 INFO SparkContext: Java version 1.8.0_332
24/12/16 18:48:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/12/16 18:48:58 INFO ResourceUtils: ==============================================================
24/12/16 18:48:58 INFO ResourceUtils: No custom resources configured for spark.driver.
24/12/16 18:48:58 INFO ResourceUtils: ==============================================================
24/12/16 18:48:58 INFO SparkContext: Submitted application: DistributedMakeExecutor
24/12/16 18:48:58 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 51200, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/12/16 18:48:58 INFO ResourceProfile: Limiting resource is cpu
24/12/16 18:48:58 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/12/16 18:48:59 INFO SecurityManager: Changing view acls to: anasmane
24/12/16 18:48:59 INFO SecurityManager: Changing modify acls to: anasmane
24/12/16 18:48:59 INFO SecurityManager: Changing view acls groups to: 
24/12/16 18:48:59 INFO SecurityManager: Changing modify acls groups to: 
24/12/16 18:48:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: anasmane; groups with view permissions: EMPTY; users with modify permissions: anasmane; groups with modify permissions: EMPTY
24/12/16 18:48:59 INFO Utils: Successfully started service 'sparkDriver' on port 41339.
24/12/16 18:48:59 INFO SparkEnv: Registering MapOutputTracker
24/12/16 18:48:59 INFO SparkEnv: Registering BlockManagerMaster
24/12/16 18:48:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/12/16 18:48:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/12/16 18:48:59 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/12/16 18:48:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e0b6704b-3563-4038-b368-0968111ebf15
24/12/16 18:48:59 INFO MemoryStore: MemoryStore started with capacity 26.5 GiB
24/12/16 18:48:59 INFO SparkEnv: Registering OutputCommitCoordinator
24/12/16 18:48:59 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/12/16 18:48:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/12/16 18:48:59 INFO SparkContext: Added JAR file:/tmp/systemes-distribues/target/distributed-make-project-1.0.jar at spark://paradoxe-1.rennes.grid5000.fr:41339/jars/distributed-make-project-1.0.jar with timestamp 1734371338809
24/12/16 18:48:59 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://172.16.101.1:3000...
24/12/16 18:48:59 INFO TransportClientFactory: Successfully created connection to /172.16.101.1:3000 after 23 ms (0 ms spent in bootstraps)
24/12/16 18:48:59 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20241216184859-0003
24/12/16 18:48:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216184859-0003/0 on worker-20241216184325-172.16.101.16-35419 (172.16.101.16:35419) with 104 core(s)
24/12/16 18:48:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216184859-0003/0 on hostPort 172.16.101.16:35419 with 104 core(s), 50.0 GiB RAM
24/12/16 18:48:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216184859-0003/1 on worker-20241216184321-172.16.101.1-45667 (172.16.101.1:45667) with 104 core(s)
24/12/16 18:48:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216184859-0003/1 on hostPort 172.16.101.1:45667 with 104 core(s), 50.0 GiB RAM
24/12/16 18:48:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216184859-0003/2 on worker-20241216184326-172.16.101.11-46793 (172.16.101.11:46793) with 104 core(s)
24/12/16 18:48:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216184859-0003/2 on hostPort 172.16.101.11:46793 with 104 core(s), 50.0 GiB RAM
24/12/16 18:48:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216184859-0003/3 on worker-20241216184327-172.16.101.24-34103 (172.16.101.24:34103) with 104 core(s)
24/12/16 18:48:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216184859-0003/3 on hostPort 172.16.101.24:34103 with 104 core(s), 50.0 GiB RAM
24/12/16 18:48:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216184859-0003/4 on worker-20241216184329-172.16.101.25-40173 (172.16.101.25:40173) with 104 core(s)
24/12/16 18:48:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216184859-0003/4 on hostPort 172.16.101.25:40173 with 104 core(s), 50.0 GiB RAM
24/12/16 18:48:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39219.
24/12/16 18:48:59 INFO NettyBlockTransferService: Server created on paradoxe-1.rennes.grid5000.fr:39219
24/12/16 18:48:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/12/16 18:48:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216184859-0003/5 on worker-20241216184326-172.16.101.26-46371 (172.16.101.26:46371) with 104 core(s)
24/12/16 18:48:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216184859-0003/5 on hostPort 172.16.101.26:46371 with 104 core(s), 50.0 GiB RAM
24/12/16 18:48:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, paradoxe-1.rennes.grid5000.fr, 39219, None)
24/12/16 18:48:59 INFO BlockManagerMasterEndpoint: Registering block manager paradoxe-1.rennes.grid5000.fr:39219 with 26.5 GiB RAM, BlockManagerId(driver, paradoxe-1.rennes.grid5000.fr, 39219, None)
24/12/16 18:48:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, paradoxe-1.rennes.grid5000.fr, 39219, None)
24/12/16 18:48:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, paradoxe-1.rennes.grid5000.fr, 39219, None)
24/12/16 18:48:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216184859-0003/1 is now RUNNING
24/12/16 18:48:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216184859-0003/0 is now RUNNING
24/12/16 18:48:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216184859-0003/5 is now RUNNING
24/12/16 18:48:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216184859-0003/3 is now RUNNING
24/12/16 18:48:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216184859-0003/2 is now RUNNING
24/12/16 18:48:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216184859-0003/4 is now RUNNING
24/12/16 18:48:59 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
