[0;33mNO_NFS mode enabled : nodes can be from different sites[0m
[0;36mReading configuration from [0;33moutput_logs_test9/with_8_machines/config8.txt[0m...
[0;32mMaster site name set to: [0;33mrennes[0m
[0;32mMaster node name set to: [0;33mparadoxe-5[0m
[0;32mMaster node IP set to: [0;33m172.16.101.5[0m
[0;32mMaster node port set to: [0;33m3000[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-6[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-7[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-9[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-22[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-24[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-25[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-26[0m
[0;36mConfiguration reading complete.[0m
[0;36mKilling ServeFile on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-6[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-6[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-7[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-7[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-9[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-9[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-22[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-22[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-24[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-24[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-25[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-25[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-26[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-26[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling FileLocatorServer on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mpkill -f java\ FileLocatorServer\ 9999[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test9[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-6[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-6[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test9[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-7[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-7[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test9[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-9[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-9[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test9[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-22[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-22[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test9[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-24[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-24[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test9[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-25[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-25[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test9[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-26[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mLaunching FileLocatorServer on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-26[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test9[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java  FileLocatorServer 9999 /tmp/systemes-distribues/src/test/resources/test9[0m
Server started on port 8888
Server started on port 8888
Server started on port 8888
Server started on port 8888
Server started on port 8888
File Locator Server is running on port 9999...
Server started on port 8888
Server started on port 8888
Server started on port 8888
[0;36mSubmitting Spark app from [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35m
        /home/anasmane/spark-3.5.3-bin-hadoop3/bin/spark-submit --master spark://172.16.101.5:3000 --driver-memory 50G --executor-memory 50G --conf 'spark.executor.extraJavaOptions=-XX:-UseGCOverheadLimit' --conf 'spark.driver.extraJavaOptions=-XX:-UseGCOverheadLimit' --deploy-mode client --class Main /tmp/systemes-distribues/target/distributed-make-project-1.0.jar /tmp/systemes-distribues/src/test/resources/test9/Makefile all spark://172.16.101.5:3000 NO_NFS
    [0m
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
[33mSkipping last target 'all' (no commands).[0m

[32m==============================[0m
[32m  Global Time : 30.219533898 seconds  [0m
[32m==============================[0m
[33m--------------------------------[0m
	[33mParsing Time           : 0.012529789 seconds[0m
	[33mGraph Build Time       : 0.009984916 seconds[0m
	[33mSpark Configuration Time: 1.152541073 seconds[0m
	[33mExecution Time         : 29.044448436 seconds[0m
[33m--------------------------------[0m
[0;36mKilling ServeFile on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-6[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-6[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-7[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-7[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-9[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-9[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-22[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-22[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-24[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-24[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-25[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-25[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-26[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-26[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling FileLocatorServer on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mpkill -f java\ FileLocatorServer\ 9999[0m
24/12/16 14:47:01 INFO SparkContext: Running Spark version 3.5.3
24/12/16 14:47:01 INFO SparkContext: OS info Linux, 5.10.0-33-amd64, amd64
24/12/16 14:47:01 INFO SparkContext: Java version 1.8.0_332
24/12/16 14:47:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/12/16 14:47:01 INFO ResourceUtils: ==============================================================
24/12/16 14:47:01 INFO ResourceUtils: No custom resources configured for spark.driver.
24/12/16 14:47:01 INFO ResourceUtils: ==============================================================
24/12/16 14:47:01 INFO SparkContext: Submitted application: DistributedMakeExecutor
24/12/16 14:47:01 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 51200, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/12/16 14:47:01 INFO ResourceProfile: Limiting resource is cpu
24/12/16 14:47:01 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/12/16 14:47:01 INFO SecurityManager: Changing view acls to: anasmane
24/12/16 14:47:01 INFO SecurityManager: Changing modify acls to: anasmane
24/12/16 14:47:01 INFO SecurityManager: Changing view acls groups to: 
24/12/16 14:47:01 INFO SecurityManager: Changing modify acls groups to: 
24/12/16 14:47:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: anasmane; groups with view permissions: EMPTY; users with modify permissions: anasmane; groups with modify permissions: EMPTY
24/12/16 14:47:01 INFO Utils: Successfully started service 'sparkDriver' on port 35021.
24/12/16 14:47:01 INFO SparkEnv: Registering MapOutputTracker
24/12/16 14:47:01 INFO SparkEnv: Registering BlockManagerMaster
24/12/16 14:47:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/12/16 14:47:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/12/16 14:47:01 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/12/16 14:47:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4a6e50af-9e0a-48ee-a758-3749138df384
24/12/16 14:47:01 INFO MemoryStore: MemoryStore started with capacity 26.5 GiB
24/12/16 14:47:01 INFO SparkEnv: Registering OutputCommitCoordinator
24/12/16 14:47:02 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/12/16 14:47:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
24/12/16 14:47:02 INFO Utils: Successfully started service 'SparkUI' on port 4041.
24/12/16 14:47:02 INFO SparkContext: Added JAR file:/tmp/systemes-distribues/target/distributed-make-project-1.0.jar at spark://paradoxe-5.rennes.grid5000.fr:35021/jars/distributed-make-project-1.0.jar with timestamp 1734356821330
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://172.16.101.5:3000...
24/12/16 14:47:02 INFO TransportClientFactory: Successfully created connection to /172.16.101.5:3000 after 21 ms (0 ms spent in bootstraps)
24/12/16 14:47:02 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20241216144702-0002
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216144702-0002/0 on worker-20241216144523-172.16.101.22-32783 (172.16.101.22:32783) with 104 core(s)
24/12/16 14:47:02 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216144702-0002/0 on hostPort 172.16.101.22:32783 with 104 core(s), 50.0 GiB RAM
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216144702-0002/1 on worker-20241216144521-172.16.101.6-45535 (172.16.101.6:45535) with 104 core(s)
24/12/16 14:47:02 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216144702-0002/1 on hostPort 172.16.101.6:45535 with 104 core(s), 50.0 GiB RAM
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216144702-0002/2 on worker-20241216144522-172.16.101.9-35663 (172.16.101.9:35663) with 104 core(s)
24/12/16 14:47:02 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216144702-0002/2 on hostPort 172.16.101.9:35663 with 104 core(s), 50.0 GiB RAM
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216144702-0002/3 on worker-20241216144523-172.16.101.24-42431 (172.16.101.24:42431) with 104 core(s)
24/12/16 14:47:02 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216144702-0002/3 on hostPort 172.16.101.24:42431 with 104 core(s), 50.0 GiB RAM
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216144702-0002/4 on worker-20241216144517-172.16.101.5-35451 (172.16.101.5:35451) with 104 core(s)
24/12/16 14:47:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40513.
24/12/16 14:47:02 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216144702-0002/4 on hostPort 172.16.101.5:35451 with 104 core(s), 50.0 GiB RAM
24/12/16 14:47:02 INFO NettyBlockTransferService: Server created on paradoxe-5.rennes.grid5000.fr:40513
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216144702-0002/5 on worker-20241216144522-172.16.101.7-45073 (172.16.101.7:45073) with 104 core(s)
24/12/16 14:47:02 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216144702-0002/5 on hostPort 172.16.101.7:45073 with 104 core(s), 50.0 GiB RAM
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216144702-0002/6 on worker-20241216144526-172.16.101.26-36403 (172.16.101.26:36403) with 104 core(s)
24/12/16 14:47:02 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216144702-0002/6 on hostPort 172.16.101.26:36403 with 104 core(s), 50.0 GiB RAM
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216144702-0002/7 on worker-20241216144524-172.16.101.25-34851 (172.16.101.25:34851) with 104 core(s)
24/12/16 14:47:02 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216144702-0002/7 on hostPort 172.16.101.25:34851 with 104 core(s), 50.0 GiB RAM
24/12/16 14:47:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/12/16 14:47:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, paradoxe-5.rennes.grid5000.fr, 40513, None)
24/12/16 14:47:02 INFO BlockManagerMasterEndpoint: Registering block manager paradoxe-5.rennes.grid5000.fr:40513 with 26.5 GiB RAM, BlockManagerId(driver, paradoxe-5.rennes.grid5000.fr, 40513, None)
24/12/16 14:47:02 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, paradoxe-5.rennes.grid5000.fr, 40513, None)
24/12/16 14:47:02 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, paradoxe-5.rennes.grid5000.fr, 40513, None)
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216144702-0002/6 is now RUNNING
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216144702-0002/0 is now RUNNING
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216144702-0002/2 is now RUNNING
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216144702-0002/1 is now RUNNING
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216144702-0002/7 is now RUNNING
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216144702-0002/3 is now RUNNING
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216144702-0002/5 is now RUNNING
24/12/16 14:47:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216144702-0002/4 is now RUNNING
24/12/16 14:47:02 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
