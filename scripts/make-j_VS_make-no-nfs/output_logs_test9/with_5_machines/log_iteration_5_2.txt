[0;33mNO_NFS mode enabled : nodes can be from different sites[0m
[0;36mReading configuration from [0;33moutput_logs_test9/with_5_machines/config5.txt[0m...
[0;32mMaster site name set to: [0;33mrennes[0m
[0;32mMaster node name set to: [0;33mparadoxe-5[0m
[0;32mMaster node IP set to: [0;33m172.16.101.5[0m
[0;32mMaster node port set to: [0;33m3000[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-6[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-7[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-9[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-22[0m
[0;36mConfiguration reading complete.[0m
[0;36mKilling ServeFile on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-6[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-6[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-7[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-7[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-9[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-9[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-22[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-22[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling FileLocatorServer on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mpkill -f java\ FileLocatorServer\ 9999[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test9[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-6[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-6[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test9[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-7[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-7[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test9[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-9[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-9[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test9[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-22[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mLaunching FileLocatorServer on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-22[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test9[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java  FileLocatorServer 9999 /tmp/systemes-distribues/src/test/resources/test9[0m
Server started on port 8888
Server started on port 8888
Server started on port 8888
Server started on port 8888
File Locator Server is running on port 9999...
Server started on port 8888
[0;36mSubmitting Spark app from [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35m
        /home/anasmane/spark-3.5.3-bin-hadoop3/bin/spark-submit --master spark://172.16.101.5:3000 --driver-memory 50G --executor-memory 50G --conf 'spark.executor.extraJavaOptions=-XX:-UseGCOverheadLimit' --conf 'spark.driver.extraJavaOptions=-XX:-UseGCOverheadLimit' --deploy-mode client --class Main /tmp/systemes-distribues/target/distributed-make-project-1.0.jar /tmp/systemes-distribues/src/test/resources/test9/Makefile all spark://172.16.101.5:3000 NO_NFS
    [0m
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
[33mSkipping last target 'all' (no commands).[0m

[32m==============================[0m
[32m  Global Time : 45.24301553 seconds  [0m
[32m==============================[0m
[33m--------------------------------[0m
	[33mParsing Time           : 0.013594006 seconds[0m
	[33mGraph Build Time       : 0.010889326 seconds[0m
	[33mSpark Configuration Time: 1.16135207 seconds[0m
	[33mExecution Time         : 44.057151073 seconds[0m
[33m--------------------------------[0m
[0;36mKilling ServeFile on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-6[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-6[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-7[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-7[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-9[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-9[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-22[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-22[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling FileLocatorServer on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mpkill -f java\ FileLocatorServer\ 9999[0m
24/12/16 14:34:28 INFO SparkContext: Running Spark version 3.5.3
24/12/16 14:34:28 INFO SparkContext: OS info Linux, 5.10.0-33-amd64, amd64
24/12/16 14:34:28 INFO SparkContext: Java version 1.8.0_332
24/12/16 14:34:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/12/16 14:34:28 INFO ResourceUtils: ==============================================================
24/12/16 14:34:28 INFO ResourceUtils: No custom resources configured for spark.driver.
24/12/16 14:34:28 INFO ResourceUtils: ==============================================================
24/12/16 14:34:28 INFO SparkContext: Submitted application: DistributedMakeExecutor
24/12/16 14:34:28 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 51200, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/12/16 14:34:28 INFO ResourceProfile: Limiting resource is cpu
24/12/16 14:34:28 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/12/16 14:34:28 INFO SecurityManager: Changing view acls to: anasmane
24/12/16 14:34:28 INFO SecurityManager: Changing modify acls to: anasmane
24/12/16 14:34:28 INFO SecurityManager: Changing view acls groups to: 
24/12/16 14:34:28 INFO SecurityManager: Changing modify acls groups to: 
24/12/16 14:34:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: anasmane; groups with view permissions: EMPTY; users with modify permissions: anasmane; groups with modify permissions: EMPTY
24/12/16 14:34:28 INFO Utils: Successfully started service 'sparkDriver' on port 44967.
24/12/16 14:34:28 INFO SparkEnv: Registering MapOutputTracker
24/12/16 14:34:28 INFO SparkEnv: Registering BlockManagerMaster
24/12/16 14:34:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/12/16 14:34:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/12/16 14:34:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/12/16 14:34:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-eddc5607-bd8a-4f47-adcf-7a7cf7a8a34a
24/12/16 14:34:28 INFO MemoryStore: MemoryStore started with capacity 26.5 GiB
24/12/16 14:34:28 INFO SparkEnv: Registering OutputCommitCoordinator
24/12/16 14:34:28 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/12/16 14:34:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
24/12/16 14:34:28 INFO Utils: Successfully started service 'SparkUI' on port 4041.
24/12/16 14:34:28 INFO SparkContext: Added JAR file:/tmp/systemes-distribues/target/distributed-make-project-1.0.jar at spark://paradoxe-5.rennes.grid5000.fr:44967/jars/distributed-make-project-1.0.jar with timestamp 1734356068248
24/12/16 14:34:29 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://172.16.101.5:3000...
24/12/16 14:34:29 INFO TransportClientFactory: Successfully created connection to /172.16.101.5:3000 after 24 ms (0 ms spent in bootstraps)
24/12/16 14:34:29 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20241216143429-0001
24/12/16 14:34:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216143429-0001/0 on worker-20241216143318-172.16.101.7-43015 (172.16.101.7:43015) with 104 core(s)
24/12/16 14:34:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216143429-0001/0 on hostPort 172.16.101.7:43015 with 104 core(s), 50.0 GiB RAM
24/12/16 14:34:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216143429-0001/1 on worker-20241216143320-172.16.101.22-37947 (172.16.101.22:37947) with 104 core(s)
24/12/16 14:34:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216143429-0001/1 on hostPort 172.16.101.22:37947 with 104 core(s), 50.0 GiB RAM
24/12/16 14:34:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216143429-0001/2 on worker-20241216143319-172.16.101.9-44983 (172.16.101.9:44983) with 104 core(s)
24/12/16 14:34:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216143429-0001/2 on hostPort 172.16.101.9:44983 with 104 core(s), 50.0 GiB RAM
24/12/16 14:34:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216143429-0001/3 on worker-20241216143318-172.16.101.6-35397 (172.16.101.6:35397) with 104 core(s)
24/12/16 14:34:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216143429-0001/3 on hostPort 172.16.101.6:35397 with 104 core(s), 50.0 GiB RAM
24/12/16 14:34:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216143429-0001/4 on worker-20241216143313-172.16.101.5-34555 (172.16.101.5:34555) with 104 core(s)
24/12/16 14:34:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216143429-0001/4 on hostPort 172.16.101.5:34555 with 104 core(s), 50.0 GiB RAM
24/12/16 14:34:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34731.
24/12/16 14:34:29 INFO NettyBlockTransferService: Server created on paradoxe-5.rennes.grid5000.fr:34731
24/12/16 14:34:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/12/16 14:34:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, paradoxe-5.rennes.grid5000.fr, 34731, None)
24/12/16 14:34:29 INFO BlockManagerMasterEndpoint: Registering block manager paradoxe-5.rennes.grid5000.fr:34731 with 26.5 GiB RAM, BlockManagerId(driver, paradoxe-5.rennes.grid5000.fr, 34731, None)
24/12/16 14:34:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, paradoxe-5.rennes.grid5000.fr, 34731, None)
24/12/16 14:34:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, paradoxe-5.rennes.grid5000.fr, 34731, None)
24/12/16 14:34:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216143429-0001/4 is now RUNNING
24/12/16 14:34:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216143429-0001/0 is now RUNNING
24/12/16 14:34:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216143429-0001/2 is now RUNNING
24/12/16 14:34:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216143429-0001/1 is now RUNNING
24/12/16 14:34:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216143429-0001/3 is now RUNNING
24/12/16 14:34:29 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
