[0;33mNO_NFS mode enabled : nodes can be from different sites[0m
[0;36mReading configuration from [0;33moutput_logs_test8/with_8_machines/config8.txt[0m...
[0;32mMaster site name set to: [0;33mrennes[0m
[0;32mMaster node name set to: [0;33mparadoxe-5[0m
[0;32mMaster node IP set to: [0;33m172.16.101.5[0m
[0;32mMaster node port set to: [0;33m3000[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-6[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-7[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-9[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-22[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-24[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-25[0m
[0;32mWorker site name set to: [0;33mrennes[0m
[0;32mAdded worker: [0;33mrennes:paradoxe-26[0m
[0;36mConfiguration reading complete.[0m
[0;36mKilling ServeFile on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-6[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-6[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-7[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-7[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-9[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-9[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-22[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-22[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-24[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-24[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-25[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-25[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-26[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-26[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling FileLocatorServer on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mpkill -f java\ FileLocatorServer\ 9999[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test8[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-6[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-6[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test8[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-7[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-7[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test8[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-9[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-9[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test8[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-22[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-22[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test8[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-24[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-24[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test8[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-25[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-25[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test8[0m
[0;36mLaunching ServeFile on [0;33mparadoxe-26[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mLaunching FileLocatorServer on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-26[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java ServeFile 8888 /tmp/systemes-distribues/src/test/resources/test8[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mcd /tmp/systemes-distribues/target/classes && java  FileLocatorServer 9999 /tmp/systemes-distribues/src/test/resources/test8[0m
Server started on port 8888
Server started on port 8888
Server started on port 8888
Server started on port 8888
Server started on port 8888
Server started on port 8888
Server started on port 8888
Server started on port 8888
File Locator Server is running on port 9999...
[0;36mSubmitting Spark app from [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35m
        /home/anasmane/spark-3.5.3-bin-hadoop3/bin/spark-submit --master spark://172.16.101.5:3000 --driver-memory 50G --executor-memory 50G --conf 'spark.executor.extraJavaOptions=-XX:-UseGCOverheadLimit' --conf 'spark.driver.extraJavaOptions=-XX:-UseGCOverheadLimit' --deploy-mode client --class Main /tmp/systemes-distribues/target/distributed-make-project-1.0.jar /tmp/systemes-distribues/src/test/resources/test8/Makefile all spark://172.16.101.5:3000 NO_NFS
    [0m
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
Error handling client: null
[33mSkipping last target 'all' (no commands).[0m

[32m==============================[0m
[32m  Global Time : 53.832423574 seconds  [0m
[32m==============================[0m
[33m--------------------------------[0m
	[33mParsing Time           : 0.2327503 seconds[0m
	[33mGraph Build Time       : 1.104273378 seconds[0m
	[33mSpark Configuration Time: 1.393556917 seconds[0m
	[33mExecution Time         : 51.101811491 seconds[0m
[33m--------------------------------[0m
[0;36mKilling ServeFile on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-6[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-6[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-7[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-7[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-9[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-9[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-22[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-22[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-24[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-24[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-25[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-25[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling ServeFile on [0;33mparadoxe-26[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-26[0;36m: [0;35mpkill -f java\ ServeFile\ 8888[0m
[0;36mKilling FileLocatorServer on [0;33mparadoxe-5[0;36m ([0;33mrennes[0;36m)...[0m
[0;36mExecuting on [0;33mrennes[0;36m -> [0;33mparadoxe-5[0;36m: [0;35mpkill -f java\ FileLocatorServer\ 9999[0m
24/12/16 13:27:44 INFO SparkContext: Running Spark version 3.5.3
24/12/16 13:27:44 INFO SparkContext: OS info Linux, 5.10.0-33-amd64, amd64
24/12/16 13:27:44 INFO SparkContext: Java version 1.8.0_332
24/12/16 13:27:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/12/16 13:27:44 INFO ResourceUtils: ==============================================================
24/12/16 13:27:44 INFO ResourceUtils: No custom resources configured for spark.driver.
24/12/16 13:27:44 INFO ResourceUtils: ==============================================================
24/12/16 13:27:44 INFO SparkContext: Submitted application: DistributedMakeExecutor
24/12/16 13:27:44 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 51200, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/12/16 13:27:44 INFO ResourceProfile: Limiting resource is cpu
24/12/16 13:27:44 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/12/16 13:27:44 INFO SecurityManager: Changing view acls to: anasmane
24/12/16 13:27:44 INFO SecurityManager: Changing modify acls to: anasmane
24/12/16 13:27:44 INFO SecurityManager: Changing view acls groups to: 
24/12/16 13:27:44 INFO SecurityManager: Changing modify acls groups to: 
24/12/16 13:27:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: anasmane; groups with view permissions: EMPTY; users with modify permissions: anasmane; groups with modify permissions: EMPTY
24/12/16 13:27:44 INFO Utils: Successfully started service 'sparkDriver' on port 33551.
24/12/16 13:27:44 INFO SparkEnv: Registering MapOutputTracker
24/12/16 13:27:44 INFO SparkEnv: Registering BlockManagerMaster
24/12/16 13:27:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/12/16 13:27:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/12/16 13:27:44 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/12/16 13:27:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-02093925-469c-4f4d-91f0-57a19fece3f7
24/12/16 13:27:44 INFO MemoryStore: MemoryStore started with capacity 26.5 GiB
24/12/16 13:27:44 INFO SparkEnv: Registering OutputCommitCoordinator
24/12/16 13:27:44 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/12/16 13:27:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
24/12/16 13:27:44 INFO Utils: Successfully started service 'SparkUI' on port 4041.
24/12/16 13:27:45 INFO SparkContext: Added JAR file:/tmp/systemes-distribues/target/distributed-make-project-1.0.jar at spark://paradoxe-5.rennes.grid5000.fr:33551/jars/distributed-make-project-1.0.jar with timestamp 1734352064061
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://172.16.101.5:3000...
24/12/16 13:27:45 INFO TransportClientFactory: Successfully created connection to /172.16.101.5:3000 after 24 ms (0 ms spent in bootstraps)
24/12/16 13:27:45 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20241216132745-0003
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216132745-0003/0 on worker-20241216132407-172.16.101.6-39977 (172.16.101.6:39977) with 104 core(s)
24/12/16 13:27:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216132745-0003/0 on hostPort 172.16.101.6:39977 with 104 core(s), 50.0 GiB RAM
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216132745-0003/1 on worker-20241216132408-172.16.101.9-36081 (172.16.101.9:36081) with 104 core(s)
24/12/16 13:27:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216132745-0003/1 on hostPort 172.16.101.9:36081 with 104 core(s), 50.0 GiB RAM
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216132745-0003/2 on worker-20241216132407-172.16.101.7-38483 (172.16.101.7:38483) with 104 core(s)
24/12/16 13:27:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216132745-0003/2 on hostPort 172.16.101.7:38483 with 104 core(s), 50.0 GiB RAM
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216132745-0003/3 on worker-20241216132412-172.16.101.26-44405 (172.16.101.26:44405) with 104 core(s)
24/12/16 13:27:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216132745-0003/3 on hostPort 172.16.101.26:44405 with 104 core(s), 50.0 GiB RAM
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216132745-0003/4 on worker-20241216132410-172.16.101.25-41255 (172.16.101.25:41255) with 104 core(s)
24/12/16 13:27:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216132745-0003/4 on hostPort 172.16.101.25:41255 with 104 core(s), 50.0 GiB RAM
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216132745-0003/5 on worker-20241216132409-172.16.101.22-33321 (172.16.101.22:33321) with 104 core(s)
24/12/16 13:27:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216132745-0003/5 on hostPort 172.16.101.22:33321 with 104 core(s), 50.0 GiB RAM
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216132745-0003/6 on worker-20241216132402-172.16.101.5-43667 (172.16.101.5:43667) with 104 core(s)
24/12/16 13:27:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216132745-0003/6 on hostPort 172.16.101.5:43667 with 104 core(s), 50.0 GiB RAM
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241216132745-0003/7 on worker-20241216132410-172.16.101.24-38865 (172.16.101.24:38865) with 104 core(s)
24/12/16 13:27:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20241216132745-0003/7 on hostPort 172.16.101.24:38865 with 104 core(s), 50.0 GiB RAM
24/12/16 13:27:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37665.
24/12/16 13:27:45 INFO NettyBlockTransferService: Server created on paradoxe-5.rennes.grid5000.fr:37665
24/12/16 13:27:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/12/16 13:27:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, paradoxe-5.rennes.grid5000.fr, 37665, None)
24/12/16 13:27:45 INFO BlockManagerMasterEndpoint: Registering block manager paradoxe-5.rennes.grid5000.fr:37665 with 26.5 GiB RAM, BlockManagerId(driver, paradoxe-5.rennes.grid5000.fr, 37665, None)
24/12/16 13:27:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, paradoxe-5.rennes.grid5000.fr, 37665, None)
24/12/16 13:27:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, paradoxe-5.rennes.grid5000.fr, 37665, None)
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216132745-0003/3 is now RUNNING
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216132745-0003/4 is now RUNNING
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216132745-0003/7 is now RUNNING
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216132745-0003/0 is now RUNNING
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216132745-0003/1 is now RUNNING
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216132745-0003/5 is now RUNNING
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216132745-0003/6 is now RUNNING
24/12/16 13:27:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241216132745-0003/2 is now RUNNING
24/12/16 13:27:45 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
